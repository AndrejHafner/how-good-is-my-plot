# How good is my plot? #

Statistical plots are an essential tool for visual presentation of information, but their quality is often questionable. In order to determine which plot properties determine its quality, we construct a dataset of statistical plots obtained from student theses. We utilize the crowdsourcing platform Amazon Mechanical Turk for plot quality evaluation through pairwise plot comparisons. And we fine-tune convolutional neural networks and use them to extract image embeddings to predict plot quality. We are unable to achieve good predictive quality, which we suspect is due to poor data quality or insufficient amount of labeled data.

## Dependencies

## Getting the data
### Google images
### DuckDuckGo
### Bing
For downloading plots from Bing, we used the code in ```bing_images_scraper.py```. In ```__main__``` function you write the plot names in ```queries_to_search``` list and run the code.
### UL Thesis Scrapper
For scrapping the PDF's from [Repository of the Uni-Lj](https://repozitorij.uni-lj.si), use the code at ```ul_thesis_scrapper.py```. In the ```__main__``` function you specify ```faculty``` parameter for which faculty you want to scrapp the PDF's and ```files``` list where you write the types of work you want to download (bachelor's, master's, phd's). 

### PDF image extractor

## Plot type classification
The code for plot type classification is gathered in folder ```plot_type_classification```.
Fine-tuning of the network that was used for plot type classification was done on Google Colab. We uploaded all the 
training images to Google Drive, to folder [```how_good_is_my_plot```](https://drive.google.com/drive/u/6/folders/1o9M7LNnwLZyOqnAfHzJeDKrS3x8PIXO1). 
If you want to run the training, you need to copy this folder to your drive, and connect it to Colab.
You should then upload the notebook ```plot_classification.ipynb``` to Colab and run it. 

## MT

You can see how did the survey on Amazon's MT look like on picture below.

![primer](link do slike)


You can calculate how much is certain survey going to cost you with ```price_calculator.py```.

Results can be obtained from the csv files found in ```src/mechanical_turk/batches``` folder.

For generating new pairs for comparisons use ```generate_pairs_based_on_scores.py```. Here you write the paths to csv files with results and call ```generate_pairs_by_scores``` function.

Analysis of the categories selected by MT workers can be seen in ```categories_analysis.ipynb```.



## Models
The code for training and testing the models that were used for quality prediction is gathered in folder ```src/plot_quality_prediction```.

### ELO ratings
Target variable for our models was generated by fitting ELO ratings on the results obtained from Mechanical Turk.
Below you can see the density of the ELO ratings calculated on the dataset that was labeled by MT workers.

![ELO count](https://github.com/AndrejHafner/how-good-is-my-plot/blob/develop/src/figures/elo_count.png)

This is the image that recieved the highest ELO score (109):

This image recieved median ELO score ():

This is the image that recieved the lowest ELO score (-86):

### Predicting quality from embeddings
Embeddings can be generated with ```extracting_embeddings.py```. 
For fitting and evaluating the models that use the embeddings for features, use ```quality_predictions.py```.

### Predicting quality by fine-tuning CNNs
Fine-tuning was done on Google Colab. To repeat it you will need to do the same setup as is described in plot type 
classification, then upload and run notebook ```plot_quality_finetuning.ipynb```.
