{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "plot_quality_finetuning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVFQ6l2he17J",
    "outputId": "6ba89f45-9e1d-4414-ca28-fb5255b93f7e"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rhcq2GawfBbd",
    "outputId": "403daf91-943a-4399-d5c0-60cc713fd7ed"
   },
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8OjUkBzzfIqV"
   },
   "source": [
    "from drive.MyDrive.how_good_is_my_plot.fine_tune_for_plots import train_model, initialize_model\n",
    "from drive.MyDrive.how_good_is_my_plot.regression_dataset import RegressionDataset\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_and_test(data_dir, num_epochs, learning_rate, regularization, batch_size, phase):\n",
    "\n",
    "    # Initialize the model for this run\n",
    "    num_classes = 1\n",
    "    input_size = 224\n",
    "    model_ft = initialize_model(num_classes, use_pretrained=True)\n",
    "\n",
    "    # Resizing and normalizing data\n",
    "    data_transforms = transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    image_datasets = {x: RegressionDataset(data_dir, f\"drive/MyDrive/how_good_is_my_plot/csv_splits/{phase}_{x}.csv\", data_transforms) for x in ['train', 'val']}\n",
    "\n",
    "    # Create training and validation dataloaders\n",
    "    dataloaders_dict = {\n",
    "        x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in\n",
    "        ['train', 'val']}\n",
    "\n",
    "    # Detect if we have a GPU available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Send the model to GPU\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    params_to_update = model_ft.parameters()\n",
    "\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=learning_rate, weight_decay=regularization)\n",
    "\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train\n",
    "    model, best_val_loss = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, device, num_epochs=num_epochs, regression=True)\n",
    "\n",
    "    # Test\n",
    "    test_dataset = RegressionDataset(data_dir, f\"drive/MyDrive/how_good_is_my_plot/csv_splits/{phase}_test.csv\", data_transforms)\n",
    "\n",
    "    # Create test dataloader\n",
    "    dataloader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "    test_loss = []\n",
    "    for inputs, labels in dataloader_test:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss.append(loss.flatten().tolist())\n",
    "    \n",
    "    # test_loss /= len(dataloader_test.dataset)\n",
    "    test_loss = [l for list in test_loss for l in list]\n",
    "    \n",
    "    return test_loss, best_val_loss\n",
    "\n",
    "def training_parameters_choice(learning_rates, lambdas, batch_sizes):\n",
    "\n",
    "    num_epochs = 30\n",
    "    num_classes = 1\n",
    "    data_dir = f\"drive/MyDrive/how_good_is_my_plot/final_plots_forMT\"\n",
    "\n",
    "    best_parameters = None\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for lr in learning_rates:\n",
    "      for reg in lambdas:\n",
    "        for bs in batch_sizes:\n",
    "          current_loss = 0\n",
    "          for split in range(1, 6):\n",
    "            phase = f'split{split}'\n",
    "            print(f'Currently on {phase} with parameters: {lr, reg, bs}')\n",
    "            test, _ = train_and_test(data_dir, num_epochs, lr, reg, bs, phase)\n",
    "            current_loss += np.mean(test)\n",
    "          current_loss /= 5\n",
    "\n",
    "          if current_loss < best_loss:\n",
    "            best_parameters = [lr, reg, bs]\n",
    "\n",
    "    return best_parameters\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puHJP4gOfShA",
    "outputId": "57731590-49b5-4ad5-8b0f-c4cceb9e278f"
   },
   "source": [
    "learning_rates = [1e-4, 1e-5, 1e-6]\n",
    "lambdas = [1e-3, 1e-5]\n",
    "batch_sizes = [20, 50]\n",
    "\n",
    "best_parameters = training_parameters_choice(learning_rates, lambdas, batch_sizes)\n",
    "# best_parameters = [1e-05, 1e-05, 50]\n",
    "print('BEST PARAMETERS:', best_parameters)\n",
    "\n",
    "data_dir = f\"drive/MyDrive/how_good_is_my_plot/final_plots_forMT\"\n",
    "test_loss, best_val_loss = train_and_test(data_dir, 30, *best_parameters, 'final')\n",
    "\n",
    "print('Best validation loss: ', best_val_loss)\n",
    "print('MSE on test data: ', np.mean(test_loss), '+-', np.std(test_loss)/np.sqrt(len(test_loss)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Currently on split1 with parameters: (0.0001, 0.001, 20)\n",
      "Initializing Datasets and Dataloaders...\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 172.3238\n",
      "val Loss: 42.5847\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 149.6264\n",
      "val Loss: 39.3108\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 126.0687\n",
      "val Loss: 66.5159\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 106.4935\n",
      "val Loss: 56.1858\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 70.4726\n",
      "val Loss: 43.8947\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 59.0512\n",
      "val Loss: 50.4508\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 51.0617\n",
      "val Loss: 45.5927\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 47.5581\n",
      "val Loss: 37.4330\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 38.2884\n",
      "val Loss: 33.7895\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 34.8576\n",
      "val Loss: 39.7444\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 30.3478\n",
      "val Loss: 63.6899\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 28.6992\n",
      "val Loss: 39.3737\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 20.6549\n",
      "val Loss: 26.8478\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 27.1849\n",
      "val Loss: 30.8099\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 19.4423\n",
      "val Loss: 35.7630\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 24.2290\n",
      "val Loss: 59.4376\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 26.6163\n",
      "val Loss: 33.5692\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 22.8383\n",
      "val Loss: 29.5233\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 16.4096\n",
      "val Loss: 28.1621\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 12.7889\n",
      "val Loss: 34.8963\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}