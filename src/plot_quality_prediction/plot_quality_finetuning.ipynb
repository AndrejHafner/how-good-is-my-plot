{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plot_quality_finetuning.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeL7PD6gKIaY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQenPyNUL_8U"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJHxiqdXMG8h"
      },
      "source": [
        "from drive.MyDrive.how_good_is_my_plot.fine_tune_for_plots import train_model, initialize_model\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# The split we are training and testing on\n",
        "split = 1\n",
        "\n",
        "# Data directory on which you want to train the model\n",
        "data_dir = f\"drive/MyDrive/how_good_is_my_plot/final_data_splits/split{split}\"\n",
        "\n",
        "# Number of classes = 1 for regression\n",
        "num_classes = 1\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 48\n",
        "\n",
        "# Number of epochs to train for  -> can leave this on 50 - the model with best validation loss will be saved.\n",
        "num_epochs = 30\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(num_classes, use_pretrained=True)\n",
        "\n",
        "# Resizing and normalizing data\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=3) for x in\n",
        "    ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "\n",
        "# you can change learning rate here --> \n",
        "learning_rate = 0.0001\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=learning_rate)\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, device, num_epochs=num_epochs)\n",
        "\n",
        "torch.save(model_ft.state_dict(), f\"drive/MyDrive/how_good_is_my_plot/cnn_weights/resnet101_phase3_l6.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}